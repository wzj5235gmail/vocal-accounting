"use client";

import { useState, useEffect, useRef } from "react";
import { Tabs, Card, Spinner, Alert, Button } from "flowbite-react";
import ExpenseModal from "@/components/ExpenseModal";
import { Expense } from "@/types/expense";
import {
  getExpenses,
  addExpense as addExpenseToDb,
  updateExpense as updateExpenseInDb,
  deleteExpense as deleteExpenseFromDb,
} from "@/services/supabase";
import { transcribeAudio } from "@/services/whisper";
import { analyzeExpenseText } from "@/services/openai";
import {
  getDefaultCurrency,
  shouldSkipConfirmation,
} from "@/services/settings";
import { useRouter } from "next/navigation";
import BottomNav from "@/components/BottomNav";
import { FFmpeg } from "@ffmpeg/ffmpeg";
import { fetchFile } from "@ffmpeg/util";
import { useLocalStorage } from '@/hooks/useLocalStorage';

interface ProcessingStatus {
  isProcessing: boolean;
  message?: string;
}

export default function Home() {
  const [expenses, setExpenses] = useState<Expense[]>([]);
  const [activeTab, setActiveTab] = useState<"input" | "list" | "stats">(
    "input"
  );
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  // å½•éŸ³ç›¸å…³çŠ¶æ€
  const [isRecording, setIsRecording] = useState(false);
  const [isExpenseModalOpen, setIsExpenseModalOpen] = useState(false);
  const [processingStatus, setProcessingStatus] = useState<ProcessingStatus>({
    isProcessing: false,
  });
  const [currentExpense, setCurrentExpense] = useState<Partial<Expense>>({});

  // å½•éŸ³ç›¸å…³å¼•ç”¨
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  // åœ¨ Home ç»„ä»¶ä¸­æ·»åŠ æ ‡ç­¾é¡µåŠ è½½çŠ¶æ€
  const [tabLoading, setTabLoading] = useState<{
    list: boolean;
    stats: boolean;
  }>({
    list: false,
    stats: false,
  });

  // Add new state for audio playback
  const [audioUrl, setAudioUrl] = useState<string | null>(null);

  // Add new state for transcription result
  const [transcriptionResult, setTranscriptionResult] = useState<string | null>(
    null
  );

  // Add new state for tap detection and tooltip
  const [showTapTooltip, setShowTapTooltip] = useState(false);
  const tapTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const [recordingStartTime, setRecordingStartTime] = useState<number>(0);

  const router = useRouter();

  // åœ¨ç»„ä»¶å†…æ·»åŠ  FFmpeg å®ä¾‹
  const ffmpegRef = useRef<FFmpeg | null>(null);
  const [ffmpegLoaded, setFfmpegLoaded] = useState(false);

  const [hasUsedBefore, setHasUsedBefore] = useLocalStorage('has-used-app', false);
  const [showHelpTip, setShowHelpTip] = useState(!hasUsedBefore);

  // åœ¨ç¬¬ä¸€æ¬¡å½•éŸ³å®Œæˆåæ ‡è®°ç”¨æˆ·å·²ä½¿ç”¨è¿‡
  const handleFirstRecordingComplete = () => {
    setHasUsedBefore(true);
    setShowHelpTip(false);
  };

  // ä¿®æ”¹ FFmpeg åŠ è½½å‡½æ•°
  useEffect(() => {
    const loadFFmpeg = async () => {
      try {
        if (!ffmpegRef.current) {
          ffmpegRef.current = new FFmpeg();
        }
        await ffmpegRef.current.load();
        setFfmpegLoaded(true);
      } catch (error) {
        console.error("Failed to load FFmpeg:", error);
      }
    };

    // åªåœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
    if (typeof window !== "undefined") {
      loadFFmpeg();
    }
  }, []);

  // ä»æ•°æ®åº“åŠ è½½æ•°æ®
  useEffect(() => {
    async function loadExpenses() {
      try {
        setIsLoading(true);
        const data = await getExpenses();
        setExpenses(data);
        setError(null);
      } catch (err: any) {
        console.error("åŠ è½½æ”¯å‡ºè®°å½•å¤±è´¥:", err);
        setError("æ— æ³•åŠ è½½æ”¯å‡ºè®°å½•ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•");
      } finally {
        setIsLoading(false);
      }
    }

    loadExpenses();
  }, []);

  // Add new useEffect for microphone permission
  useEffect(() => {
    const requestMicrophonePermission = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        // Stop the tracks immediately since we don't need them yet
        stream.getTracks().forEach((track) => track.stop());
      } catch (err) {
        console.error("æ— æ³•è®¿é—®éº¦å…‹é£:", err);
        setError("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆéº¦å…‹é£æƒé™");
      }
    };

    requestMicrophonePermission();
  }, []); // Empty dependency array means this runs once on mount

  // æ·»åŠ æ”¯å‡ºè®°å½•
  const addExpense = async (expense: Expense) => {
    try {
      const newExpense = await addExpenseToDb(expense);
      setExpenses((prev) => [newExpense, ...prev]);
      setIsExpenseModalOpen(false);
      setActiveTab("list"); // è‡ªåŠ¨åˆ‡æ¢åˆ°åˆ—è¡¨é¡µé¢
    } catch (err: any) {
      console.error("æ·»åŠ æ”¯å‡ºè®°å½•å¤±è´¥:", err);
      setError("æ·»åŠ æ”¯å‡ºè®°å½•å¤±è´¥ï¼Œè¯·é‡è¯•");
    }
  };

  // æ›´æ–°æ”¯å‡ºè®°å½•
  const updateExpense = async (expense: Expense) => {
    try {
      const updatedExpense = await updateExpenseInDb(expense);
      setExpenses((prev) =>
        prev.map((item) =>
          item.id === updatedExpense.id ? updatedExpense : item
        )
      );
    } catch (err: any) {
      console.error("æ›´æ–°æ”¯å‡ºè®°å½•å¤±è´¥:", err);
      setError("æ›´æ–°æ”¯å‡ºè®°å½•å¤±è´¥ï¼Œè¯·é‡è¯•");
    }
  };

  // åˆ é™¤æ”¯å‡ºè®°å½•
  const deleteExpense = async (id: string) => {
    try {
      await deleteExpenseFromDb(id);
      setExpenses((prev) => prev.filter((item) => item.id !== id));
    } catch (err: any) {
      console.error("åˆ é™¤æ”¯å‡ºè®°å½•å¤±è´¥:", err);
      setError("åˆ é™¤æ”¯å‡ºè®°å½•å¤±è´¥ï¼Œè¯·é‡è¯•");
    }
  };

  const getMimeType = (): string => {
    if (typeof window !== "undefined" && typeof navigator !== "undefined") {
      const ua = navigator.userAgent.toLowerCase();
      if (/iphone|ipad|ipod|mac/.test(ua) && !/chrome/.test(ua)) {
        return "audio/mp4";
      } else {
        return "audio/webm";
      }
    }
    return "audio/mp4";
  };

  const mimeType = getMimeType();
  console.log(`mimeType:${mimeType}`);

  // ä¿®æ”¹éŸ³é¢‘å¤„ç†é€»è¾‘
  const convertAudioFormat = async (audioBlob: Blob): Promise<Blob> => {
    if (mimeType !== "audio/mp4" || !ffmpegLoaded || !ffmpegRef.current) {
      return audioBlob;
    }

    try {
      const ffmpeg = ffmpegRef.current;
      const inputFileName = "input.m4a";
      const outputFileName = "output.wav";

      // å†™å…¥è¾“å…¥æ–‡ä»¶
      ffmpeg.writeFile(inputFileName, await fetchFile(audioBlob));

      // è½¬æ¢æ ¼å¼
      await ffmpeg.exec(["-i", inputFileName, outputFileName]);

      // è¯»å–è¾“å‡ºæ–‡ä»¶
      const data = await ffmpeg.readFile(outputFileName);
      return new Blob([data], { type: "audio/wav" });
    } catch (error) {
      console.error("Audio conversion failed:", error);
      return audioBlob;
    }
  };

  // ä¿®æ”¹ startRecording å‡½æ•°
  const startRecording = async (e: React.MouseEvent | React.TouchEvent) => {
    e.preventDefault();
    setError(null);

    // å¦‚æœå·²ç»åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢
    if (isRecording) {
      await stopRecording(e);
      return;
    }

    // Clear any existing tooltip timeout
    if (tapTimeoutRef.current) {
      clearTimeout(tapTimeoutRef.current);
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // ç¡®ä¿ä¹‹å‰çš„ MediaRecorder å·²ç»åœæ­¢å’Œæ¸…ç†
      if (mediaRecorderRef.current) {
        mediaRecorderRef.current.stream
          .getTracks()
          .forEach((track) => track.stop());
      }

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start();
      setRecordingStartTime(Date.now());
      setIsRecording(true);

      // Set recording timeout (30 seconds)
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
      recordingTimeoutRef.current = setTimeout(() => {
        if (isRecording && mediaRecorderRef.current) {
          stopRecording(new Event("timeout") as unknown as React.MouseEvent);
        }
      }, 30000);
    } catch (err) {
      console.error("æ— æ³•è®¿é—®éº¦å…‹é£:", err);
      setError("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆéº¦å…‹é£æƒé™");
      setIsRecording(false);
    }
  };

  // ä¿®æ”¹ stopRecording å‡½æ•°
  const stopRecording = async (
    e: React.MouseEvent | React.TouchEvent | Event
  ) => {
    e.preventDefault();

    // æ¸…é™¤è¶…æ—¶è®¡æ—¶å™¨
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = null;
    }

    // å¦‚æœæ²¡æœ‰åœ¨å½•éŸ³ï¼Œç›´æ¥è¿”å›
    if (!isRecording || !mediaRecorderRef.current) {
      setIsRecording(false);
      return;
    }

    // Show tooltip if recording duration was too short
    if (Date.now() - recordingStartTime < 3000) {
      setShowTapTooltip(true);
      tapTimeoutRef.current = setTimeout(() => {
        setShowTapTooltip(false);
      }, 2000);

      // Stop and cleanup recording
      if (mediaRecorderRef.current) {
        try {
          mediaRecorderRef.current.stop();
          mediaRecorderRef.current.stream
            .getTracks()
            .forEach((track) => track.stop());
        } catch (err) {
          console.error("åœæ­¢å½•éŸ³æ—¶å‡ºé”™:", err);
        }
        setIsRecording(false);
        return;
      }
    }

    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      try {
        mediaRecorderRef.current.stop();
        setIsRecording(false);

        // å¤„ç†å½•éŸ³ç»“æœ
        mediaRecorderRef.current.onstop = async () => {
          const audioBlob = new Blob(audioChunksRef.current, {
            type: mimeType,
          });
          const url = URL.createObjectURL(audioBlob);
          setAudioUrl(url);

          setProcessingStatus({
            isProcessing: true,
            message: "æ­£åœ¨å¤„ç†å½•éŸ³...",
          });
          try {
            const convertedBlob = await convertAudioFormat(audioBlob);
            const text = await transcribeAudio(convertedBlob, "wav");
            setTranscriptionResult(text);
            console.log("è½¬å½•ç»“æœ:", text);

            // ä½¿ç”¨OpenAIåˆ†ææ–‡æœ¬
            const result = await analyzeExpenseText(text);
            console.log("åˆ†æç»“æœ:", result);

            // åˆ›å»ºæ”¯å‡ºè®°å½•
            const expense: Expense = {
              id: crypto.randomUUID(),
              amount: Number(result.amount || 0),
              currency: result.currency || getDefaultCurrency(),
              category: result.category || "å…¶ä»–",
              date: result.date || new Date().toISOString().split("T")[0],
              description: result.description || "",
              createdAt: new Date().toISOString(),
            };

            if (shouldSkipConfirmation()) {
              await addExpense(expense);
            } else {
              setCurrentExpense(expense);
              setIsExpenseModalOpen(true);
            }
          } catch (error: any) {
            console.error("å¤„ç†å½•éŸ³æ—¶å‡ºé”™:", error);
            setError(error.message || "å¤„ç†å½•éŸ³æ—¶å‡ºé”™ï¼Œè¯·é‡è¯•");
          } finally {
            setProcessingStatus({ isProcessing: false });

            // å…³é—­æ‰€æœ‰éŸ³è½¨
            const tracks = mediaRecorderRef.current?.stream.getTracks();
            tracks?.forEach((track) => track.stop());
          }
        };
      } catch (err) {
        console.error("åœæ­¢å½•éŸ³æ—¶å‡ºé”™:", err);
        setIsRecording(false);
      }
    }
  };

  // æ·»åŠ ç»„ä»¶å¸è½½æ—¶çš„æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      if (mediaRecorderRef.current) {
        try {
          mediaRecorderRef.current.stream
            .getTracks()
            .forEach((track) => track.stop());
        } catch (err) {
          console.error("æ¸…ç†å½•éŸ³èµ„æºæ—¶å‡ºé”™:", err);
        }
      }
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
      if (tapTimeoutRef.current) {
        clearTimeout(tapTimeoutRef.current);
      }
    };
  }, []);

  // Add cleanup function for audio URL
  useEffect(() => {
    return () => {
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  return (
    <div className="min-h-screen bg-gray-50 dark:bg-gray-900 p-4 pb-20 flex flex-col">
      {/* ä¸»è¦å†…å®¹åŒºåŸŸ */}
      <div className="flex-1 flex flex-col items-center justify-center relative">
        {/* é¦–æ¬¡ä½¿ç”¨æç¤º */}
        {showHelpTip && (
          <div className="absolute top-20 left-1/2 transform -translate-x-1/2 -translate-y-full 
                         bg-blue-50 dark:bg-blue-900 p-4 rounded-lg shadow-lg max-w-xs 
                         text-center animate-bounce-gentle">
            <p className="text-blue-800 dark:text-blue-200 text-sm">
              ğŸ‘‹ æ¬¢è¿ä½¿ç”¨è¯­éŸ³è®°è´¦ï¼
              <br />
              æŒ‰ä½ä¸‹æ–¹æŒ‰é’®å¼€å§‹å½•éŸ³
            </p>
            <div className="absolute bottom-0 left-1/2 transform -translate-x-1/2 translate-y-1/2">
              <svg className="w-4 h-4 text-blue-50 dark:text-blue-900" fill="currentColor" viewBox="0 0 24 24">
                <path d="M12 16L6 10H18L12 16Z" />
              </svg>
            </div>
          </div>
        )}

        {/* å½•éŸ³æŒ‰é’® */}
        <button
          onTouchStart={startRecording}
          onTouchEnd={stopRecording}
          onMouseDown={startRecording}
          onMouseUp={stopRecording}
          onMouseLeave={stopRecording}
          className={`w-32 h-32 rounded-full flex items-center justify-center shadow-lg 
                     transition-all duration-200 transform hover:scale-105 active:scale-95 mb-20
                     select-none touch-none relative
                     ${isRecording ? "bg-red-500 hover:bg-red-600" : "bg-blue-500 hover:bg-blue-600"}
                     ${showHelpTip ? "animate-pulse-gentle" : ""}`}
          disabled={processingStatus.isProcessing}
        >
          {/* {processingStatus.isProcessing ? (
            <div className="animate-spin rounded-full h-8 w-8 border-4 border-white border-t-transparent"></div>
          ) : ( */}
          <svg
            className="w-16 h-16 text-white pointer-events-none"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            {isRecording ? (
              // å½•éŸ³ä¸­å›¾æ ‡ï¼ˆæ³¢å½¢åŠ¨ç”»ï¼‰
              <path
                strokeLinecap="round"
                strokeLinejoin="round"
                strokeWidth={2}
                d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
              >
                <animate
                  attributeName="opacity"
                  values="1;0.5;1"
                  dur="2s"
                  repeatCount="indefinite"
                />
              </path>
            ) : (
              // éº¦å…‹é£å›¾æ ‡
              <path
                strokeLinecap="round"
                strokeLinejoin="round"
                strokeWidth={2}
                d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
              />
            )}
          </svg>
          {/* )} */}
        </button>

        {/* å½•éŸ³æç¤ºæ–‡å­— */}
        <div className="text-gray-600 dark:text-gray-400 mb-8 text-center space-y-2">
          <p>
            {isRecording ? (
              <span className="animate-pulse">æ¾å¼€ç»“æŸå½•éŸ³</span>
            ) : (
              <span>æŒ‰ä½å¼€å§‹å½•éŸ³</span>
            )}
          </p>
          {!isRecording && !processingStatus.isProcessing && (
            <p className="text-sm text-gray-500 dark:text-gray-500">
              è¯•è¯•è¯´ï¼š"ä»Šå¤©åœ¨æ²ƒå°”ç›æ¶ˆè´¹100åŠ å¸"
            </p>
          )}
        </div>

        {/* åº•éƒ¨åŠŸèƒ½æç¤º */}
        {showHelpTip && (
          <div className="fixed bottom-20 left-4 right-4 text-center">
            <div className="inline-block bg-gray-50 dark:bg-gray-800 
                          text-gray-600 dark:text-gray-400 text-xs px-4 py-2 
                          rounded-full shadow-sm border border-gray-200 dark:border-gray-700">
              åœ¨åº•éƒ¨å¯¼èˆªæ æŸ¥çœ‹è®°å½•å’Œç»Ÿè®¡ ğŸ‘‡
            </div>
          </div>
        )}
      </div>

      {/* é”™è¯¯æç¤º */}
      {error && (
        <div className="fixed top-4 left-4 right-4">
          <div className="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative">
            {error}
          </div>
        </div>
      )}

      {/* åŠ è½½æŒ‡ç¤ºå™¨ */}
      {processingStatus.isProcessing && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center">
          <div className="bg-white dark:bg-gray-800 p-8 rounded-lg shadow-lg flex flex-col items-center">
            <Spinner size="xl" className="mx-auto" />
            <p className="mt-4 text-base text-gray-700 dark:text-gray-300">
              {processingStatus.message || "å¤„ç†ä¸­..."}
            </p>
          </div>
        </div>
      )}

      {/* æ¨¡æ€æ¡† */}
      <ExpenseModal
        isOpen={isExpenseModalOpen}
        isProcessing={processingStatus.isProcessing}
        expense={currentExpense}
        onClose={() => setIsExpenseModalOpen(false)}
        onSave={addExpense}
      />

      <BottomNav />

      {/* <ExpenseInputSection
        onAddExpense={addExpense}
        isProcessing={processingStatus.isProcessing}
        processingStatus={processingStatus}
        setProcessingStatus={setProcessingStatus}
      /> */}
    </div>
  );
}

// Add this to your global CSS or as a style tag
const tooltipAnimation = `
@keyframes fadeOut {
  0% { opacity: 1; }
  70% { opacity: 1; }
  100% { opacity: 0; }
}
.animate-fade-out {
  animation: fadeOut 2s forwards;
}
`;

// æ·»åŠ åˆ°å…¨å±€æ ·å¼
const newAnimations = `
@keyframes bounce-gentle {
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-10px); }
}

@keyframes pulse-gentle {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.8; }
}

.animate-bounce-gentle {
  animation: bounce-gentle 2s infinite;
}

.animate-pulse-gentle {
  animation: pulse-gentle 2s infinite;
}
`;
